{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gunescepic/InstrumentSegmentation/blob/master/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2EM3LMopLTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import json\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ybd5GEKpLTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.backends.cudnn\n",
        "import cv2\n",
        "from albumentations.pytorch.transforms import img_to_tensor\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC0mU-NbpLTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import tqdm\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXSb8szApLTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from albumentations import (\n",
        "    HorizontalFlip,\n",
        "    VerticalFlip,\n",
        "    Normalize,\n",
        "    Compose,\n",
        "    PadIfNeeded,\n",
        "    RandomCrop,\n",
        "    CenterCrop\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U2-I99spLT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_transform(p=1):\n",
        "    return Compose([\n",
        "        Normalize(p=1)\n",
        "    ], p=p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBAMbTtlpLT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cuda(x):\n",
        "   \treturn x.cuda() if torch.cuda.is_available() else x\n",
        "### VALIDATION #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vr8HMJ6pLUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_binary(model, criterion, valid_loader, num_classes=None):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        losses = []\n",
        "        jaccard = []\n",
        "        for inputs, targets in valid_loader:\n",
        "            inputs = utils.cuda(inputs)\n",
        "            targets = utils.cuda(targets)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            losses.append(loss.item())\n",
        "            jaccard += get_jaccard(targets, (outputs > 0).float())\n",
        "        valid_loss = np.mean(losses)  # type: float\n",
        "        valid_jaccard = np.mean(jaccard).astype(np.float64)\n",
        "        print('Valid loss: {:.5f}, jaccard: {:.5f}'.format(valid_loss, valid_jaccard))\n",
        "        metrics = {'valid_loss': valid_loss, 'jaccard_loss': valid_jaccard}\n",
        "        return metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMCPNsFdpLUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_jaccard(y_true, y_pred):\n",
        "    epsilon = 1e-15\n",
        "    intersection = (y_pred * y_true).sum(dim=-2).sum(dim=-1)\n",
        "    union = y_true.sum(dim=-2).sum(dim=-1) + y_pred.sum(dim=-2).sum(dim=-1)\n",
        "    return list(((intersection + epsilon) / (union - intersection + epsilon)).data.cpu().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWIn6jcRpLUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_multi(model: nn.Module, criterion, valid_loader, num_classes):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        losses = []\n",
        "        confusion_matrix = np.zeros(\n",
        "            (num_classes, num_classes), dtype=np.uint32)\n",
        "        for inputs, targets in valid_loader:\n",
        "            inputs = utils.cuda(inputs)\n",
        "            targets = utils.cuda(targets)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            losses.append(loss.item())\n",
        "            output_classes = outputs.data.cpu().numpy().argmax(axis=1)\n",
        "            target_classes = targets.data.cpu().numpy()\n",
        "            confusion_matrix += calculate_confusion_matrix_from_arrays(\n",
        "                output_classes, target_classes, num_classes)\n",
        "        confusion_matrix = confusion_matrix[1:, 1:]  # exclude background\n",
        "        valid_loss = np.mean(losses)  # type: float\n",
        "        ious = {'iou_{}'.format(cls + 1): iou\n",
        "                for cls, iou in enumerate(calculate_iou(confusion_matrix))}\n",
        "        dices = {'dice_{}'.format(cls + 1): dice\n",
        "                 for cls, dice in enumerate(calculate_dice(confusion_matrix))}\n",
        "        average_iou = np.mean(list(ious.values()))\n",
        "        average_dices = np.mean(list(dices.values()))\n",
        "        print(\n",
        "            'Valid loss: {:.4f}, average IoU: {:.4f}, average Dice: {:.4f}'.format(valid_loss,\n",
        "                                                                                   average_iou,\n",
        "                                                                                   average_dices))\n",
        "        metrics = {'valid_loss': valid_loss, 'iou': average_iou}\n",
        "        metrics.update(ious)\n",
        "        metrics.update(dices)\n",
        "        return metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ej0-_1VpLUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_confusion_matrix_from_arrays(prediction, ground_truth, nr_labels):\n",
        "    replace_indices = np.vstack((\n",
        "        ground_truth.flatten(),\n",
        "        prediction.flatten())\n",
        "    ).T\n",
        "    confusion_matrix, _ = np.histogramdd(\n",
        "        replace_indices,\n",
        "        bins=(nr_labels, nr_labels),\n",
        "        range=[(0, nr_labels), (0, nr_labels)]\n",
        "    )\n",
        "    confusion_matrix = confusion_matrix.astype(np.uint32)\n",
        "    return confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxKee-SUpLUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_iou(confusion_matrix):\n",
        "    ious = []\n",
        "    for index in range(confusion_matrix.shape[0]):\n",
        "        true_positives = confusion_matrix[index, index]\n",
        "        false_positives = confusion_matrix[:, index].sum() - true_positives\n",
        "        false_negatives = confusion_matrix[index, :].sum() - true_positives\n",
        "        denom = true_positives + false_positives + false_negatives\n",
        "        if denom == 0:\n",
        "            iou = 0\n",
        "        else:\n",
        "            iou = float(true_positives) / denom\n",
        "        ious.append(iou)\n",
        "    return ious"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2MJfY78pLUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_dice(confusion_matrix):\n",
        "    dices = []\n",
        "    for index in range(confusion_matrix.shape[0]):\n",
        "        true_positives = confusion_matrix[index, index]\n",
        "        false_positives = confusion_matrix[:, index].sum() - true_positives\n",
        "        false_negatives = confusion_matrix[index, :].sum() - true_positives\n",
        "        denom = 2 * true_positives + false_positives + false_negatives\n",
        "        if denom == 0:\n",
        "            dice = 0\n",
        "        else:\n",
        "            dice = 2 * float(true_positives) / denom\n",
        "        dices.append(dice)\n",
        "    return dices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ucwbXy1pLU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_ids = '0,1,2'\n",
        "lr =  0.0001\n",
        "batch_size = 6\n",
        "n_epochs = 10\n",
        "jaccard_weight = 0.3\n",
        "train_crop_height = 1024\n",
        "train_crop_width = 1280\n",
        "val_crop_height = 1024 \n",
        "val_crop_width = 1024 \n",
        "fold = 4\n",
        "segmentation_type = 'binary'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97ZcThThpLU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = Path('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjgT1F8WpLVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = data_path / 'train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEDSf8VtpLVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cropped_train_path = data_path / 'cropped_train' # new path for cropped images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzNofUR4pLVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_height, original_width = 1080, 1920\n",
        "height, width = 1024, 1280\n",
        "h_start, w_start = 28, 320"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SmQ9TB4pLVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "binary_factor = 255\n",
        "parts_factor = 85\n",
        "instrument_factor = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZieMA8uQpLVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "worker = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyQ5KeIipLVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if segmentation_type == 'parts':\n",
        "    num_classes = 4 #not sure\n",
        "elif segmentation_type == 'instruments':\n",
        "    num_classes = 16\n",
        "else:\n",
        "    num_classes = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5OM2aGzpLVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = 'runs/debug'\n",
        "Path(root).mkdir(exist_ok=True, parents=True)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36S-TU98pLVw",
        "colab_type": "text"
      },
      "source": [
        "########### LOAD DATA ################################<br>\n",
        "import torchvision.transforms.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrSBd8XYpLVy",
        "colab_type": "text"
      },
      "source": [
        "def img_to_tensor(im, normalize=None):<br>\n",
        "    tensor = torch.from_numpy(np.moveaxis(im / (255. if im.dtype == np.uint8 else 1), -1, 0).astype(np.float32))<br>\n",
        "    if normalize is not None:<br>\n",
        "        return F.normalize(tensor, **normalize)<br>\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoGlpU1NpLVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "class RoboticsDataset(Dataset):\n",
        "    def __init__(self, file_names, to_augment=False, transform=None, mode='train', problem_type=None):\n",
        "        self.file_names = file_names\n",
        "        self.to_augment = to_augment\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "        self.problem_type = problem_type\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "    def __getitem__(self, idx):\n",
        "        img_file_name = self.file_names[idx]\n",
        "        image = load_image(img_file_name)\n",
        "        mask = load_mask(img_file_name, segmentation_type)\n",
        "        data = {\"image\": image, \"mask\": mask}\n",
        "        augmented = self.transform(**data)\n",
        "        image, mask = augmented[\"image\"], augmented[\"mask\"]\n",
        "        if self.mode == 'train':\n",
        "            if self.problem_type == 'binary':\n",
        "                return img_to_tensor(image), torch.from_numpy(np.expand_dims(mask, 0)).float()\n",
        "            else:\n",
        "                return img_to_tensor(image), torch.from_numpy(mask).long()\n",
        "        else:\n",
        "            return img_to_tensor(image), str(img_file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYRUIPSQpLV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(path):\n",
        "    img = cv2.imread(str(path))\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I29F6VTSpLV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mask(path, problem_type):\n",
        "    if problem_type == 'binary':\n",
        "        mask_folder = 'binary_masks'\n",
        "        factor = binary_factor\n",
        "    elif problem_type == 'parts':\n",
        "        mask_folder = 'parts_masks'\n",
        "        factor = parts_factor\n",
        "    elif problem_type == 'instruments':\n",
        "        factor = instrument_factor\n",
        "        mask_folder = 'instruments_masks'\n",
        "    mask = cv2.imread(str(path).replace('images', mask_folder).replace('jpg', 'png'), 0)\n",
        "    return (mask / factor).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk_ybbo3pLV_",
        "colab_type": "text"
      },
      "source": [
        "########### PREPROCESS DATA ##########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kMEpDx_pLWA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<br>\n",
        "[1] Merge masks with different instruments into one binary mask<br>\n",
        "[2] Crop black borders from images and masks<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnH514JspLWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "0b29b129-515e-4fdf-f7ee-cb17e56b149a"
      },
      "source": [
        "from tqdm import tqdm\n",
        "for instrument_index in range(1, 5):\n",
        "    instrument_folder = 'seq_' + str(instrument_index)\n",
        "    (cropped_train_path / instrument_folder / 'left_frames').mkdir(exist_ok=True, parents=True)\n",
        "    binary_mask_folder = (cropped_train_path / instrument_folder / 'binary_masks')\n",
        "    binary_mask_folder.mkdir(exist_ok=True, parents=True)\n",
        "    parts_mask_folder = (cropped_train_path / instrument_folder / 'parts_masks')\n",
        "    parts_mask_folder.mkdir(exist_ok=True, parents=True)\n",
        "    instrument_mask_folder = (cropped_train_path / instrument_folder / 'instruments_masks')\n",
        "    instrument_mask_folder.mkdir(exist_ok=True, parents=True)\n",
        "    mask_folders = list((train_path / instrument_folder / 'labels').glob('*'))\n",
        "    # mask_folders = [x for x in mask_folders if 'Other' not in str(mask_folders)]\n",
        "    for file_name in tqdm(list((train_path / instrument_folder / 'left_frames').glob('*'))):\n",
        "        img = cv2.imread(str(file_name))\n",
        "        old_h, old_w, _ = img.shape\n",
        "        img = img[h_start: h_start + height, w_start: w_start + width]\n",
        "        cv2.imwrite(str(cropped_train_path / instrument_folder / 'left_frames' / (file_name.stem + '.png')), img,\n",
        "                    [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
        "        mask_binary = np.zeros((old_h, old_w))\n",
        "        mask_parts = np.zeros((old_h, old_w))\n",
        "        mask_instruments = np.zeros((old_h, old_w))\n",
        "        for mask_folder in mask_folders:\n",
        "            mask = cv2.imread(str(mask_folder / file_name.name), 0)\n",
        "            if 'Bipolar_Forceps' in str(mask_folder):\n",
        "                mask_instruments[mask > 0] = 1\n",
        "            elif 'Prograsp_Forceps' in str(mask_folder):\n",
        "                mask_instruments[mask > 0] = 2\n",
        "            elif 'Large_Needle_Driver' in str(mask_folder):\n",
        "                mask_instruments[mask > 0] = 3\n",
        "            elif 'Vessel_Sealer' in str(mask_folder):\n",
        "                mask_instruments[mask > 0] = 4\n",
        "            elif 'Grasping_Retractor' in str(mask_folder):\n",
        "                mask_instruments[mask > 0] = 5\n",
        "            elif 'Monopolar_Curved_Scissors' in str(mask_folder):\n",
        "                mask_instruments[mask > 0] = 6\n",
        "            elif 'Other' in str(mask_folder):\n",
        "                mask_instruments[mask > 0] = 7\n",
        "            if 'Other' not in str(mask_folder):\n",
        "                mask_binary += mask\n",
        "                mask_parts[mask == 10] = 1  # Shaft\n",
        "                mask_parts[mask == 20] = 2  # Wrist\n",
        "                mask_parts[mask == 30] = 3  # Claspers\n",
        "        mask_binary = (mask_binary[h_start: h_start + height, w_start: w_start + width] > 0).astype(\n",
        "            np.uint8) * binary_factor\n",
        "        mask_parts = (mask_parts[h_start: h_start + height, w_start: w_start + width]).astype(\n",
        "            np.uint8) * parts_factor\n",
        "        mask_instruments = (mask_instruments[h_start: h_start + height, w_start: w_start + width]).astype(\n",
        "            np.uint8) * instrument_factor\n",
        "        cv2.imwrite(str(binary_mask_folder / file_name.name), mask_binary)\n",
        "        cv2.imwrite(str(parts_mask_folder / file_name.name), mask_parts)\n",
        "        cv2.imwrite(str(instrument_mask_folder / file_name.name), mask_instruments)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zEQ0-CrpLWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_split(fold):\n",
        "  \t#4 fold cross validation can be changed\n",
        "    folds = {1: [2, 3, 4],\n",
        "             2: [1, 3, 4],\n",
        "             3: [1, 2, 4],\n",
        "             4: [1, 2, 3]}\n",
        "    train_path = data_path \n",
        "    train_file_names = []\n",
        "    val_file_names = []\n",
        "    for instrument_id in range(1, 5):\n",
        "        print(instrument_id)\n",
        "        print(folds[fold])\n",
        "        if instrument_id in folds[fold]:\n",
        "            val_file_names += list((train_path / ('seq_' + str(instrument_id)) / 'left_frames').glob('*'))\n",
        "        else:\n",
        "            train_file_names += list((train_path / ('seq_' + str(instrument_id)) / 'left_frames').glob('*'))\n",
        "    return train_file_names, val_file_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znTCSqQspLWM",
        "colab_type": "text"
      },
      "source": [
        "########### CREATE MODEL ############################"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGElQ_E3pLWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import models\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82K-EW1QpLWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_, out):\n",
        "    return nn.Conv2d(in_, out, 3, padding=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ampAS0_hpLWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvRelu(nn.Module):\n",
        "    def __init__(self, in_: int, out: int):\n",
        "        super(ConvRelu, self).__init__()\n",
        "        self.conv = conv3x3(in_, out)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUxYdGL1pLWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        if is_deconv:\n",
        "            self.block = nn.Sequential(\n",
        "                ConvRelu(in_channels, middle_channels),\n",
        "                nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,\n",
        "                                   padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        else:\n",
        "            self.block = nn.Sequential(\n",
        "                nn.Upsample(scale_factor=2, mode='bilinear'),\n",
        "                ConvRelu(in_channels, middle_channels),\n",
        "                ConvRelu(middle_channels, out_channels),\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv1ZdB_5pLWl",
        "colab_type": "text"
      },
      "source": [
        "# Unet with encoder pretrained vgg16 ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc3pYPKspLWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "class UNet16(nn.Module):\n",
        "    def __init__(self, num_classes=1, num_filters=32, pretrained=False):\n",
        "        \"\"\"\n",
        "        :param num_classes:\n",
        "        :param num_filters:\n",
        "        :param pretrained:\n",
        "            False - no pre-trained network used\n",
        "            True - encoder pre-trained with VGG11\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.encoder = torchvision.models.vgg16(pretrained=pretrained).features\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Sequential(self.encoder[0],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[2],\n",
        "                                   self.relu)\n",
        "        self.conv2 = nn.Sequential(self.encoder[5],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[7],\n",
        "                                   self.relu)\n",
        "        self.conv3 = nn.Sequential(self.encoder[10],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[12],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[14],\n",
        "                                   self.relu)\n",
        "        self.conv4 = nn.Sequential(self.encoder[17],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[19],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[21],\n",
        "                                   self.relu)\n",
        "        self.conv5 = nn.Sequential(self.encoder[24],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[26],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[28],\n",
        "                                   self.relu)\n",
        "        self.center = DecoderBlock(512, num_filters * 8 * 2, num_filters * 8)\n",
        "        self.dec5 = DecoderBlock(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8)\n",
        "        self.dec4 = DecoderBlock(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8)\n",
        "        self.dec3 = DecoderBlock(256 + num_filters * 8, num_filters * 4 * 2, num_filters * 2)\n",
        "        self.dec2 = DecoderBlock(128 + num_filters * 2, num_filters * 2 * 2, num_filters)\n",
        "        self.dec1 = ConvRelu(64 + num_filters, num_filters)\n",
        "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(self.pool(conv1))\n",
        "        conv3 = self.conv3(self.pool(conv2))\n",
        "        conv4 = self.conv4(self.pool(conv3))\n",
        "        conv5 = self.conv5(self.pool(conv4))\n",
        "        center = self.center(self.pool(conv5))\n",
        "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
        "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
        "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
        "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
        "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
        "        if self.num_classes > 1:\n",
        "            x_out = F.log_softmax(self.final(dec1), dim=1)\n",
        "        else:\n",
        "            x_out = self.final(dec1)\n",
        "        return x_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgXnEhhOpLWp",
        "colab_type": "text"
      },
      "source": [
        "########### TRAIN MODEL ##############################<br>\n",
        " ADD LOSS ####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4lX83OMpLWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LossBinary:\n",
        "    #Loss defined as alpha BCE - (1 - alpha) SoftJaccard\n",
        "    def __init__(self, jaccard_weight=0):\n",
        "        self.nll_loss = nn.BCEWithLogitsLoss()\n",
        "        self.jaccard_weight = jaccard_weight\n",
        "    def __call__(self, outputs, targets):\n",
        "        loss = (1 - self.jaccard_weight) * self.nll_loss(outputs, targets)\n",
        "        if self.jaccard_weight:\n",
        "            eps = 1e-15\n",
        "            jaccard_target = (targets == 1).float()\n",
        "            jaccard_output = F.sigmoid(outputs)\n",
        "            intersection = (jaccard_output * jaccard_target).sum()\n",
        "            union = jaccard_output.sum() + jaccard_target.sum()\n",
        "            loss -= self.jaccard_weight * torch.log((intersection + eps) / (union - intersection + eps))\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdpW95UspLWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LossMulti:\n",
        "    def __init__(self, jaccard_weight=0, class_weights=None, num_classes=1):\n",
        "        if class_weights is not None:\n",
        "            nll_weight = utils.cuda(\n",
        "                torch.from_numpy(class_weights.astype(np.float32)))\n",
        "        else:\n",
        "            nll_weight = None\n",
        "        self.nll_loss = nn.NLLLoss2d(weight=nll_weight)\n",
        "        self.jaccard_weight = jaccard_weight\n",
        "        self.num_classes = num_classes\n",
        "    def __call__(self, outputs, targets):\n",
        "        loss = (1 - self.jaccard_weight) * self.nll_loss(outputs, targets)\n",
        "        if self.jaccard_weight:\n",
        "            eps = 1e-15\n",
        "            for cls in range(self.num_classes):\n",
        "                jaccard_target = (targets == cls).float()\n",
        "                jaccard_output = outputs[:, cls].exp()\n",
        "                intersection = (jaccard_output * jaccard_target).sum()\n",
        "                union = jaccard_output.sum() + jaccard_target.sum()\n",
        "                loss -= torch.log((intersection + eps) / (union - intersection + eps)) * self.jaccard_weight\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L_XvNbApLWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = UNet16(1, pretrained=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vLndCKmpLW0",
        "colab_type": "text"
      },
      "source": [
        "cuda dependency check later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLlynUzVpLW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device_ids = '0,1,2'\n",
        "if torch.cuda.is_available():\n",
        "    # if device_ids:\n",
        "    #     device_ids = list(map(int, device_ids.split(',')))\n",
        "    # else:\n",
        "    device_ids = None\n",
        "    model = nn.DataParallel(model, device_ids=device_ids).cuda()\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "if segmentation_type == 'binary':\n",
        "    loss = LossBinary(jaccard_weight=jaccard_weight)\n",
        "else:\n",
        "    loss = LossMulti(num_classes=num_classes, jaccard_weight=jaccard_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VP_NSXtpLW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw0a1TWgpLW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file_names, val_file_names = get_split(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q93k_BKapLW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b406a0ec-0bd1-45c8-ab53-7bf6a1dc3eae"
      },
      "source": [
        "print('num train = {}, num_val = {}'.format(len(train_file_names), len(val_file_names)))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num train = 0, num_val = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOCd8STkpLW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_transform(p=1):\n",
        "    return Compose([\n",
        "        PadIfNeeded(min_height=train_crop_height, min_width=train_crop_width, p=1),\n",
        "        RandomCrop(height=train_crop_height, width=train_crop_width, p=1),\n",
        "        VerticalFlip(p=0.5),\n",
        "        HorizontalFlip(p=0.5),\n",
        "        Normalize(p=1)\n",
        "    ], p=p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHxCq3RxpLXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_transform(p=1):\n",
        "    return Compose([\n",
        "        PadIfNeeded(min_height=val_crop_height, min_width=val_crop_width, p=1),\n",
        "        CenterCrop(height=val_crop_height, width=val_crop_width, p=1),\n",
        "        Normalize(p=1)\n",
        "    ], p=p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07kg4H6MpLXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(\n",
        "\tdataset = RoboticsDataset(train_file_names, transform = train_transform(p = 1), problem_type = segmentation_type),\n",
        "\tshuffle = True,\n",
        "\tnum_workers = workers,\n",
        "\tbatch_size = batch_size,\n",
        "\tpin_memory = torch.cuda.is_available()\n",
        "\t)\n",
        "valid_loader = DataLoader(\n",
        "\tdataset = RoboticsDataset(val_file_names, transform = val_transform(p = 1), problem_type = segmentation_type),\n",
        "\tshuffle = True,\n",
        "\tnum_workers = workers,\n",
        "\tbatch_size = batch_size\n",
        "\t)\n",
        "# root.joinpath('params.json').write_text(\n",
        "#         json.dumps(vars(args), indent=True, sort_keys=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKlqRT6epLXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if segmentation_type == 'binary':\n",
        "    valid = validation_binary\n",
        "else:\n",
        "    valid = validation_multi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1aU-0jIpLXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_event(log, step, **data):\n",
        "    data['step'] = step\n",
        "    data['dt'] = datetime.now().isoformat()\n",
        "    log.write(json.dumps(data, sort_keys=True))\n",
        "    log.write('\\n')\n",
        "    log.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-9646XdpLXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_crop_size(image_height, image_width):\n",
        "    \"\"\"Checks if image size divisible by 32.\n",
        "    Args:\n",
        "        image_height:\n",
        "        image_width:\n",
        "    Returns:\n",
        "        True if both height and width divisible by 32 and False otherwise.\n",
        "    \"\"\"\n",
        "    return image_height % 32 == 0 and image_width % 32 == 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-41FEZTypLXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, criterion, train_loader, valid_loader, validation, init_optimizer, n_epochs=None, fold=None,\n",
        "          num_classes=None):\n",
        "    lr = lr\n",
        "    n_epochs = n_epochs\n",
        "    optimizer = init_optimizer(lr)\n",
        "    root = Path(root)\n",
        "    model_path = root / 'model_{fold}.pt'.format(fold=fold)\n",
        "    if model_path.exists():\n",
        "        state = torch.load(str(model_path))\n",
        "        epoch = state['epoch']\n",
        "        step = state['step']\n",
        "        model.load_state_dict(state['model'])\n",
        "        print('Restored model, epoch {}, step {:,}'.format(epoch, step))\n",
        "    else:\n",
        "        epoch = 1\n",
        "        step = 0\n",
        "    save = lambda ep: torch.save({\n",
        "        'model': model.state_dict(),\n",
        "        'epoch': ep,\n",
        "        'step': step,\n",
        "    }, str(model_path))\n",
        "    report_each = 10\n",
        "    log = root.joinpath('train_{fold}.log'.format(fold=fold)).open('at', encoding='utf8')\n",
        "    valid_losses = []\n",
        "    for epoch in range(epoch, n_epochs + 1):\n",
        "        model.train()\n",
        "        random.seed()\n",
        "        tq = tqdm.tqdm(total=(len(train_loader) * batch_size))\n",
        "        tq.set_description('Epoch {}, lr {}'.format(epoch, lr))\n",
        "        losses = []\n",
        "        tl = train_loader\n",
        "        try:\n",
        "            mean_loss = 0\n",
        "            for i, (inputs, targets) in enumerate(tl):\n",
        "                inputs = cuda(inputs)\n",
        "                with torch.no_grad():\n",
        "                    targets = cuda(targets)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                optimizer.zero_grad()\n",
        "                batch_size = inputs.size(0)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                step += 1\n",
        "                tq.update(batch_size)\n",
        "                losses.append(loss.item())\n",
        "                mean_loss = np.mean(losses[-report_each:])\n",
        "                tq.set_postfix(loss='{:.5f}'.format(mean_loss))\n",
        "                if i and i % report_each == 0:\n",
        "                    write_event(log, step, loss=mean_loss)\n",
        "            write_event(log, step, loss=mean_loss)\n",
        "            tq.close()\n",
        "            save(epoch + 1)\n",
        "            valid_metrics = validation(model, criterion, valid_loader, num_classes)\n",
        "            write_event(log, step, **valid_metrics)\n",
        "            valid_loss = valid_metrics['valid_loss']\n",
        "            valid_losses.append(valid_loss)\n",
        "        except KeyboardInterrupt:\n",
        "            tq.close()\n",
        "            print('Ctrl+C, saving snapshot')\n",
        "            save(epoch)\n",
        "            print('done.')\n",
        "            return\n",
        "train(\n",
        "    init_optimizer=lambda lr: Adam(model.parameters(), lr=lr),\n",
        "    args=args,\n",
        "    model=model,\n",
        "    criterion=loss,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    validation=valid,\n",
        "    fold=4, #args.fold\n",
        "    num_classes=num_classes\n",
        ")\n",
        "############# GENERATE MASKS ##########################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMOC9-MRpLXb",
        "colab_type": "text"
      },
      "source": [
        " CHECK THIS METHOD ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es9XeRUVpLXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, from_file_names, batch_size, to_path, problem_type, img_transform):\n",
        "    loader = DataLoader(\n",
        "        dataset=RoboticsDataset(from_file_names, transform=img_transform, mode='predict', problem_type=problem_type),\n",
        "        shuffle=False,\n",
        "        batch_size=6,\n",
        "        num_workers=workers,\n",
        "        pin_memory=torch.cuda.is_available()\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        for batch_num, (inputs, paths) in enumerate(tqdm(loader, desc='Predict')):\n",
        "            inputs = utils.cuda(inputs)\n",
        "            outputs = model(inputs)\n",
        "            for i, image_name in enumerate(paths):\n",
        "                if problem_type == 'binary':\n",
        "                    factor = prepare_data.binary_factor\n",
        "                    t_mask = (F.sigmoid(outputs[i, 0]).data.cpu().numpy() * factor).astype(np.uint8)\n",
        "                elif problem_type == 'parts':\n",
        "                    factor = prepare_data.parts_factor\n",
        "                    t_mask = (outputs[i].data.cpu().numpy().argmax(axis=0) * factor).astype(np.uint8)\n",
        "                elif problem_type == 'instruments':\n",
        "                    factor = prepare_data.instrument_factor\n",
        "                    t_mask = (outputs[i].data.cpu().numpy().argmax(axis=0) * factor).astype(np.uint8)\n",
        "                h, w = t_mask.shape\n",
        "                full_mask = np.zeros((original_height, original_width))\n",
        "                full_mask[h_start:h_start + h, w_start:w_start + w] = t_mask\n",
        "                instrument_folder = Path(paths[i]).parent.parent.name\n",
        "                (to_path / instrument_folder).mkdir(exist_ok=True, parents=True)\n",
        "                cv2.imwrite(str(to_path / instrument_folder / (Path(paths[i]).stem + '.png')), full_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laurd3b9pLXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = UNet16(num_classes = num_classes)\n",
        "### needs path to saved trained model above ###\n",
        "state = torch.load(str(Path(model_path)).joinpath('model_{fold}.pt'.format(fold=args.fold)))\n",
        "state = {key.replace('module.', ''): value for key, value in state['model'].items()}\n",
        "model.load_state_dict(state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrP7GEhypLXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLMDGdqipLXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZQg8iRlpLXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, file_names = get_split(fold)\n",
        "print('num file_names = {}'.format(len(file_names)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKRs09DspLXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_path = 'predictions/unet16/binary'\n",
        "output_path.mkdir(exist_ok=True, parents=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgUtu6w-pLX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(model, file_names, batch_size, output_path, problem_type=segmentation_type,\n",
        "        img_transform=img_transform(p=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGHVr_MupLX9",
        "colab_type": "text"
      },
      "source": [
        "########### EVALUATE ################################"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9NycLYdpLX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_dice = []\n",
        "result_jaccard = []\n",
        "train_path = 'predictions/unet16'\n",
        "target_path = 'data/cropped_train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x14sUDFTpLYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if segmentation_type == 'binary':\n",
        "    for instrument_id in tqdm(range(1, 5)):\n",
        "        instrument_dataset_name = 'seq_' + str(instrument_id)\n",
        "        for file_name in (\n",
        "                train_path / instrument_dataset_name / 'binary_masks').glob('*'):\n",
        "            y_true = (cv2.imread(str(file_name), 0) > 0).astype(np.uint8)\n",
        "            pred_file_name = target_path / 'binary' / instrument_dataset_name / file_name.name\n",
        "            pred_image = (cv2.imread(str(pred_file_name), 0) > 255 * 0.5).astype(np.uint8)\n",
        "            y_pred = pred_image[h_start:h_start + height, w_start:w_start + width]\n",
        "            result_dice += [dice(y_true, y_pred)]\n",
        "            result_jaccard += [jaccard(y_true, y_pred)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yM8EKsjpLYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elif args.problem_type == 'parts':\n",
        "    for instrument_id in tqdm(range(1, 5)):\n",
        "        instrument_dataset_name = 'seq_' + str(instrument_id)\n",
        "        for file_name in (\n",
        "                train_path / instrument_dataset_name / 'parts_masks').glob('*'):\n",
        "            y_true = cv2.imread(str(file_name), 0)\n",
        "            pred_file_name = target_path / 'parts' / instrument_dataset_name / file_name.name\n",
        "            y_pred = cv2.imread(str(pred_file_name), 0)[h_start:h_start + height, w_start:w_start + width]\n",
        "            result_dice += [general_dice(y_true, y_pred)]\n",
        "            result_jaccard += [general_jaccard(y_true, y_pred)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpNQLsEMpLYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elif args.problem_type == 'instruments':\n",
        "    for instrument_id in tqdm(range(1, 5)):\n",
        "        instrument_dataset_name = 'seq_' + str(instrument_id)\n",
        "        for file_name in (\n",
        "                train_path / instrument_dataset_name / 'instruments_masks').glob('*'):\n",
        "            y_true = cv2.imread(str(file_name), 0)\n",
        "            pred_file_name = target_path / 'instruments' / instrument_dataset_name / file_name.name\n",
        "            y_pred = cv2.imread(str(pred_file_name), 0)[h_start:h_start + height, w_start:w_start + width]\n",
        "            result_dice += [general_dice(y_true, y_pred)]\n",
        "            result_jaccard += [general_jaccard(y_true, y_pred)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RadYdQwpLYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Dice = ', np.mean(result_dice), np.std(result_dice))\n",
        "print('Jaccard = ', np.mean(result_jaccard), np.std(result_jaccard))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}