{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import utils\n", "from torch import nn\n", "import torch"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def validation_binary(model, criterion, valid_loader, num_classes=None):\n", "    with torch.no_grad():\n", "        model.eval()\n", "        losses = []\n", "        jaccard = []\n", "        for inputs, targets in valid_loader:\n", "            inputs = utils.cuda(inputs)\n", "            targets = utils.cuda(targets)\n", "            outputs = model(inputs)\n", "            loss = criterion(outputs, targets)\n", "            losses.append(loss.item())\n", "            jaccard += get_jaccard(targets, (outputs > 0).float())\n", "        valid_loss = np.mean(losses)  # type: float\n", "        valid_jaccard = np.mean(jaccard).astype(np.float64)\n", "        print('Valid loss: {:.5f}, jaccard: {:.5f}'.format(valid_loss, valid_jaccard))\n", "        metrics = {'valid_loss': valid_loss, 'jaccard_loss': valid_jaccard}\n", "        return metrics"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_jaccard(y_true, y_pred):\n", "    epsilon = 1e-15\n", "    intersection = (y_pred * y_true).sum(dim=-2).sum(dim=-1)\n", "    union = y_true.sum(dim=-2).sum(dim=-1) + y_pred.sum(dim=-2).sum(dim=-1)\n", "    return list(((intersection + epsilon) / (union - intersection + epsilon)).data.cpu().numpy())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def validation_multi(model: nn.Module, criterion, valid_loader, num_classes):\n", "    with torch.no_grad():\n", "        model.eval()\n", "        losses = []\n", "        confusion_matrix = np.zeros(\n", "            (num_classes, num_classes), dtype=np.uint32)\n", "        for inputs, targets in valid_loader:\n", "            inputs = utils.cuda(inputs)\n", "            targets = utils.cuda(targets)\n", "            outputs = model(inputs)\n", "            loss = criterion(outputs, targets)\n", "            losses.append(loss.item())\n", "            output_classes = outputs.data.cpu().numpy().argmax(axis=1)\n", "            target_classes = targets.data.cpu().numpy()\n", "            confusion_matrix += calculate_confusion_matrix_from_arrays(\n", "                output_classes, target_classes, num_classes)\n", "        confusion_matrix = confusion_matrix[1:, 1:]  # exclude background\n", "        valid_loss = np.mean(losses)  # type: float\n", "        ious = {'iou_{}'.format(cls + 1): iou\n", "                for cls, iou in enumerate(calculate_iou(confusion_matrix))}\n", "        dices = {'dice_{}'.format(cls + 1): dice\n", "                 for cls, dice in enumerate(calculate_dice(confusion_matrix))}\n", "        average_iou = np.mean(list(ious.values()))\n", "        average_dices = np.mean(list(dices.values()))\n", "        print(\n", "            'Valid loss: {:.4f}, average IoU: {:.4f}, average Dice: {:.4f}'.format(valid_loss,\n", "                                                                                   average_iou,\n", "                                                                                   average_dices))\n", "        metrics = {'valid_loss': valid_loss, 'iou': average_iou}\n", "        metrics.update(ious)\n", "        metrics.update(dices)\n", "        return metrics"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def calculate_confusion_matrix_from_arrays(prediction, ground_truth, nr_labels):\n", "    replace_indices = np.vstack((\n", "        ground_truth.flatten(),\n", "        prediction.flatten())\n", "    ).T\n", "    confusion_matrix, _ = np.histogramdd(\n", "        replace_indices,\n", "        bins=(nr_labels, nr_labels),\n", "        range=[(0, nr_labels), (0, nr_labels)]\n", "    )\n", "    confusion_matrix = confusion_matrix.astype(np.uint32)\n", "    return confusion_matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def calculate_iou(confusion_matrix):\n", "    ious = []\n", "    for index in range(confusion_matrix.shape[0]):\n", "        true_positives = confusion_matrix[index, index]\n", "        false_positives = confusion_matrix[:, index].sum() - true_positives\n", "        false_negatives = confusion_matrix[index, :].sum() - true_positives\n", "        denom = true_positives + false_positives + false_negatives\n", "        if denom == 0:\n", "            iou = 0\n", "        else:\n", "            iou = float(true_positives) / denom\n", "        ious.append(iou)\n", "    return ious"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def calculate_dice(confusion_matrix):\n", "    dices = []\n", "    for index in range(confusion_matrix.shape[0]):\n", "        true_positives = confusion_matrix[index, index]\n", "        false_positives = confusion_matrix[:, index].sum() - true_positives\n", "        false_negatives = confusion_matrix[index, :].sum() - true_positives\n", "        denom = 2 * true_positives + false_positives + false_negatives\n", "        if denom == 0:\n", "            dice = 0\n", "        else:\n", "            dice = 2 * float(true_positives) / denom\n", "        dices.append(dice)\n", "    return dices"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}